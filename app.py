# app.py
import os
import json
import time
from pathlib import Path

import streamlit as st
from openai import OpenAI


# -----------------------------
# Paths
# -----------------------------
DEFAULT_CONFIG_PATH = "configs/diagnosis_config.json"
KNOWLEDGE_DIR = Path("knowledge")


# -----------------------------
# Loaders
# -----------------------------
def load_json(path: str) -> dict:
    p = Path(path)
    if not p.exists():
        return {}
    with p.open("r", encoding="utf-8") as f:
        return json.load(f)


def load_text(path: Path, max_chars: int = 9000) -> str:
    if not path.exists():
        return ""
    return path.read_text(encoding="utf-8", errors="ignore")[:max_chars]


def build_knowledge_digest(max_chars_each: int = 7000) -> str:
    parts = []
    for fn in ["positions.md", "shifts.md", "methodology.md", "question_bank.md", "examples_transcripts.md"]:
        p = KNOWLEDGE_DIR / fn
        if p.exists():
            parts.append(f"\n\n--- FILE: {fn} ---\n{load_text(p, max_chars_each)}")
    return "".join(parts).strip()


def model_name(cfg: dict) -> str:
    return cfg.get("runtime", {}).get("model", os.environ.get("AI_NEO_MODEL", "gpt-4.1-mini"))


def max_turns(cfg: dict) -> int:
    d = cfg.get("diagnosis", {})
    return int(d.get("hard_stop_at_questions", d.get("max_questions_total", 30) or 30))


# -----------------------------
# Session state
# -----------------------------
def init_state(cfg: dict):
    st.session_state.setdefault("cfg", cfg)
    st.session_state.setdefault("turn", 0)
    st.session_state.setdefault("max_turns", max_turns(cfg))
    st.session_state.setdefault("stage", "intake")
    st.session_state.setdefault("history", [])
    st.session_state.setdefault("current_q", None)
    st.session_state.setdefault("name", "")
    st.session_state.setdefault("request", "")
    st.session_state.setdefault("finished", False)
    st.session_state.setdefault("client_report", None)
    st.session_state.setdefault("knowledge_digest", None)
    st.session_state.setdefault("debug_last_error", None)
    st.session_state.setdefault("ui_error", "")


def reset_all():
    for k in list(st.session_state.keys()):
        del st.session_state[k]
    st.rerun()


# -----------------------------
# OpenAI helpers
# -----------------------------
def get_client() -> OpenAI:
    return OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))


def compact_context(state: dict, keep_last: int = 6) -> str:
    hist = state["history"][-keep_last:]
    lines = []
    for item in hist:
        lines.append(f"[{item.get('stage','')}] Q: {item.get('q','')}\nA: {item.get('a','')}")
    return "\n\n".join(lines).strip()


QUESTION_SCHEMA = {
    "name": "next_question",
    "schema": {
        "type": "object",
        "additionalProperties": False,
        "properties": {
            "question_id": {"type": "string"},
            "stage": {"type": "string"},
            "intent": {"type": "string"},
            "question_text": {"type": "string"},
            "answer_type": {"type": "string", "enum": ["text", "single", "multi"]},
            "options": {"type": "array", "items": {"type": "string"}},
            "required": {"type": "boolean"},
            "should_stop": {"type": "boolean"},
            "why_next": {"type": "string"},
        },
        "required": [
            "question_id",
            "stage",
            "intent",
            "question_text",
            "answer_type",
            "options",
            "required",
            "should_stop",
            "why_next",
        ],
    },
}


def call_llm_next_question(state: dict) -> dict:
    cfg = state["cfg"]
    if state["knowledge_digest"] is None:
        state["knowledge_digest"] = build_knowledge_digest()

    kd = state["knowledge_digest"]
    ctx = compact_context(state, keep_last=6)

    asked_intents = [h.get("intent") for h in state["history"]]
    last_intent = asked_intents[-1] if asked_intents else ""

    system_text = f"""
–¢—ã ‚Äî AI-–¥–∏–∞–≥–Ω–æ—Å—Ç Neo Potentials (—Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫).
–ü—Ä–∞–≤–∏–ª–∞:
- –ù–µ –ø–æ–≤—Ç–æ—Ä—è–π –≤–æ–ø—Ä–æ—Å—ã –ø–æ —Å–º—ã—Å–ª—É. –°–º–æ—Ç—Ä–∏ –∏—Å—Ç–æ—Ä–∏—é.
- –ù–µ –∑–∞–¥–∞–≤–∞–π "–ø–æ—á–µ–º—É?" –±–æ–ª—å—à–µ –æ–¥–Ω–æ–≥–æ —Ä–∞–∑–∞ –ø–æ–¥—Ä—è–¥.
- –≠—Ç–∞–ø—ã: intake -> now -> childhood -> behavior -> antipattern -> shifts(if needed) -> wrap.
- –ï—Å–ª–∏ answer_type=single/multi, options –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å >=2. –ò–Ω–∞—á–µ answer_type=text.
- –ö–æ—Ä–æ—Ç–∫–æ –∏ –ø–æ-—á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏.
- –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û –∑–Ω–∞–Ω–∏—è –∏–∑ –¥–∞–π–¥–∂–µ—Å—Ç–∞ –Ω–∏–∂–µ.

–î–ê–ô–î–ñ–ï–°–¢:
{kd}
""".strip()

    user_text = f"""
–°–æ—Å—Ç–æ—è–Ω–∏–µ:
turn={state["turn"]} –∏–∑ {state["max_turns"]}
stage={state["stage"]}
name={state.get("name","") or "(–Ω–µ—Ç)"}
request={state.get("request","") or "(–Ω–µ—Ç)"}
last_intent={last_intent or "(–Ω–µ—Ç)"}
asked_intents={asked_intents}

–ò—Å—Ç–æ—Ä–∏—è:
{ctx or "(–ø–æ–∫–∞ –Ω–µ—Ç)"}

–°—Ñ–æ—Ä–º–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å (1 —à—Ç.) –ø–æ —Å—Ö–µ–º–µ.
""".strip()

    client = get_client()

    resp = client.responses.create(
        model=model_name(cfg),
        input=[
            {"role": "system", "content": system_text},
            {"role": "user", "content": user_text},
        ],
        response_format={"type": "json_schema", "json_schema": QUESTION_SCHEMA},
        max_output_tokens=650,
    )
    data = resp.output_parsed
    if not isinstance(data, dict):
        return {}
    return data


def next_question(state: dict) -> dict:
    # retry x1; –∏–Ω–∞—á–µ fallback
    try:
        q = call_llm_next_question(state)
        if isinstance(q, dict) and q.get("question_text"):
            return q
    except Exception as e:
        st.session_state["debug_last_error"] = str(e)

    # Fallback (–ù–ï —Å—Ç–æ–ø–æ—Ä–∏–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è)
    return {
        "question_id": f"fallback_{state['turn']}",
        "stage": state["stage"],
        "intent": "fallback",
        "question_text": "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –ø–∞—É–∑–∞. –ï—Å–ª–∏ –º–æ–∂–µ—à—å ‚Äî –Ω–∞–ø–∏—à–∏ 1 –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –ø—Ä–∏–º–µ—Ä (—Å–∏—Ç—É–∞—Ü–∏—è ‚Üí —á—Ç–æ —Å–¥–µ–ª–∞–ª–∞ ‚Üí —Ä–µ–∑—É–ª—å—Ç–∞—Ç). –ï—Å–ª–∏ –Ω–µ —Ö–æ—á–µ—à—å ‚Äî –ø—Ä–æ—Å—Ç–æ –Ω–∞–∂–º–∏ ¬´–î–∞–ª–µ–µ¬ª.",
        "answer_type": "text",
        "options": [],
        "required": False,          # –í–ê–ñ–ù–û: —á—Ç–æ–±—ã ¬´–î–∞–ª–µ–µ¬ª —Ä–∞–±–æ—Ç–∞–ª–æ –¥–∞–∂–µ –ø—É—Å—Ç—ã–º
        "should_stop": False,
        "why_next": "Fallback –ø—Ä–∏ –æ—à–∏–±–∫–µ/–ª–∏–º–∏—Ç–∞—Ö.",
    }


# -----------------------------
# Validation
# -----------------------------
def normalize_q_type(q: dict):
    q_type = q.get("answer_type", "text")
    opts = q.get("options") or []
    if q_type in ("single", "multi") and len(opts) < 2:
        q_type = "text"
        opts = []
    return q_type, opts


def validate_answer(q: dict, answer) -> bool:
    if not q.get("required", True):
        return True
    q_type, opts = normalize_q_type(q)

    if q_type == "single":
        return isinstance(answer, str) and answer.strip() != ""
    if q_type == "multi":
        return isinstance(answer, list) and len(answer) > 0
    return isinstance(answer, str) and answer.strip() != ""


# -----------------------------
# UI
# -----------------------------
st.set_page_config(page_title="NEO –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞", page_icon="üß≠", layout="centered")

cfg = load_json(DEFAULT_CONFIG_PATH)
init_state(cfg)

st.title("–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–æ–≤")
st.caption("–§–æ—Ä–º–∞—Ç: –∂–∏–≤–æ–π —Ä–∞–∑–±–æ—Ä. –í–æ–ø—Ä–æ—Å—ã —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç –ò–ò –ø–æ –ª–æ–≥–∏–∫–µ —ç—Ç–∞–ø–æ–≤. –í –∫–æ–Ω—Ü–µ ‚Äî –∫–æ—Ä–æ—Ç–∫–∞—è –∫–∞—Ä—Ç–∏–Ω–∞ + —Å–ª–µ–¥—É—é—â–∏–π —à–∞–≥.")

if st.button("üîÑ –°–±—Ä–æ—Å–∏—Ç—å –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É"):
    reset_all()

st.write(f"–•–æ–¥: –≤–æ–ø—Ä–æ—Å {min(st.session_state['turn'] + 1, st.session_state['max_turns'])} –∏–∑ {st.session_state['max_turns']} | —Ñ–∞–∑–∞: {st.session_state['stage']}")

# –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∑–∞–º–µ—Ç–Ω—É—é –æ—à–∏–±–∫—É UI (–µ—Å–ª–∏ –±—ã–ª–∞)
if st.session_state.get("ui_error"):
    st.error(st.session_state["ui_error"])
    st.session_state["ui_error"] = ""

# Finish (–ø–æ–∫–∞ –ø—Ä–æ—Å—Ç–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é)
if st.session_state["finished"] or st.session_state["turn"] >= st.session_state["max_turns"]:
    st.session_state["finished"] = True
    st.success("–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ ‚úÖ")
    st.markdown(f"**–ò–º—è:** {st.session_state.get('name') or '‚Äî'}")
    st.markdown(f"**–ó–∞–ø—Ä–æ—Å:** {st.session_state.get('request') or '‚Äî'}")

    # –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç
    lines = []
    for item in st.session_state["history"]:
        lines.append(f"{item.get('stage','')} | {item.get('intent','')}\nQ: {item.get('q','')}\nA: {item.get('a','')}\n")
    txt = "\n".join(lines)
    st.download_button("üì• –°–∫–∞—á–∞—Ç—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç (TXT)", data=txt.encode("utf-8"), file_name="neo_transcript.txt", mime="text/plain")

    if st.session_state.get("debug_last_error"):
        st.caption("–¢–µ—Ö. –ª–æ–≥ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ –º–∞—Å—Ç–µ—Ä—É): –æ—à–∏–±–∫–∞ –≤—ã–∑–æ–≤–∞ –º–æ–¥–µ–ª–∏ –±—ã–ª–∞ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–∞ –≤ session.")
    st.stop()

# Create question if missing
if st.session_state["current_q"] is None:
    q = next_question(st.session_state)
    if q.get("stage"):
        st.session_state["stage"] = q["stage"]
    st.session_state["current_q"] = q
else:
    q = st.session_state["current_q"]

q_type, options = normalize_q_type(q)

# ---- FORM (–≤–∞–∂–Ω–æ –¥–ª—è –º–æ–±–∏–ª–∫–∏) ----
with st.form(key="neo_form", clear_on_submit=True):
    st.markdown(f"### {q.get('question_text','').strip()}")

    answer = None
    if q_type == "single":
        answer = st.radio("–í—ã–±–µ—Ä–∏ –æ–¥–∏–Ω –≤–∞—Ä–∏–∞–Ω—Ç:", options)
    elif q_type == "multi":
        answer = st.multiselect("–í—ã–±–µ—Ä–∏ –≤–∞—Ä–∏–∞–Ω—Ç—ã:", options)
    else:
        answer = st.text_area("–û—Ç–≤–µ—Ç:", height=130)

    col1, col2 = st.columns([1, 1])
    with col1:
        submitted = st.form_submit_button("–î–∞–ª–µ–µ ‚ûú")
    with col2:
        finish_now = st.form_submit_button("–ó–∞–≤–µ—Ä—à–∏—Ç—å —Å–µ–π—á–∞—Å")

if finish_now:
    st.session_state["finished"] = True
    st.rerun()

if submitted:
    if not validate_answer(q, answer):
        # —ç—Ç–æ –±—É–¥–µ—Ç –≤–∏–¥–Ω–æ –°–†–ê–ó–£ —Å–≤–µ—Ä—Ö—É –Ω–∞ —ç–∫—Ä–∞–Ω–µ
        st.session_state["ui_error"] = "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–∞–ø–∏—à–∏ –æ—Ç–≤–µ—Ç (–∏–ª–∏ –≤—ã–±–µ—Ä–∏ –≤–∞—Ä–∏–∞–Ω—Ç), —á—Ç–æ–±—ã –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å."
        st.rerun()

    # Save intake quickly (–ø—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞)
    intent = q.get("intent", "")
    if intent in ("ask_name", "name") and isinstance(answer, str):
        st.session_state["name"] = answer.strip()
    if intent in ("ask_request", "request") and isinstance(answer, str):
        st.session_state["request"] = answer.strip()

    # –ó–∞–ø–∏—Å—å –∏—Å—Ç–æ—Ä–∏–∏
    st.session_state["history"].append(
        {
            "turn": st.session_state["turn"],
            "question_id": q.get("question_id", f"q_{st.session_state['turn']}"),
            "intent": intent,
            "stage": q.get("stage", st.session_state["stage"]),
            "q": q.get("question_text", ""),
            "a": answer if isinstance(answer, str) else json.dumps(answer, ensure_ascii=False),
        }
    )

    st.session_state["turn"] += 1
    st.session_state["current_q"] = None

    # –µ—Å–ª–∏ –º–æ–¥–µ–ª—å —Å–∫–∞–∑–∞–ª–∞ —Å—Ç–æ–ø ‚Äî –∑–∞–≤–µ—Ä—à–∞–µ–º (–ø–æ—Å–ª–µ –º–∏–Ω–∏–º—É–º–∞ –≤–æ–ø—Ä–æ—Å–æ–≤)
    if q.get("should_stop") is True and st.session_state["turn"] >= 8:
        st.session_state["finished"] = True

    st.rerun()
    