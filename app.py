# app.py
import os
import json
import time
from pathlib import Path
import streamlit as st

# OpenAI SDK (new style)
from openai import OpenAI


# -----------------------------
# Config + Knowledge loaders
# -----------------------------
DEFAULT_CONFIG_PATH = "configs/diagnosis_config.json"
KNOWLEDGE_DIR = Path("knowledge")
PROMPTS_DIR = Path("prompts")


def load_json(path: str) -> dict:
    p = Path(path)
    if not p.exists():
        return {}
    with p.open("r", encoding="utf-8") as f:
        return json.load(f)


def load_text(path: Path, max_chars: int = 12000) -> str:
    if not path.exists():
        return ""
    txt = path.read_text(encoding="utf-8", errors="ignore")
    return txt[:max_chars]


def build_knowledge_digest(max_chars_each: int = 8000) -> str:
    # –±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –∫—Ä–∞—Ç–∫–∏–π –¥–∞–π–¥–∂–µ—Å—Ç, —á—Ç–æ–±—ã –Ω–µ —Å–Ω–æ—Å–∏—Ç—å –ª–∏–º–∏—Ç—ã —Ç–æ–∫–µ–Ω–æ–≤
    parts = []
    files_order = [
        "positions.md",
        "shifts.md",
        "methodology.md",
        "question_bank.md",
        "examples_transcripts.md",
    ]
    for fn in files_order:
        p = KNOWLEDGE_DIR / fn
        if p.exists():
            parts.append(f"\n\n--- FILE: {fn} ---\n{load_text(p, max_chars_each)}")
    return "".join(parts).strip()


def model_name(cfg: dict) -> str:
    # –ú–æ–∂–Ω–æ –∑–∞–¥–∞—Ç—å –≤ configs/diagnosis_config.json: { "runtime": { "model": "gpt-4.1-mini" } }
    return (
        cfg.get("runtime", {})
        .get("model", os.environ.get("AI_NEO_MODEL", "gpt-4.1-mini"))
    )


def max_turns(cfg: dict) -> int:
    return int(cfg.get("diagnosis", {}).get("hard_stop_at_questions", cfg.get("diagnosis", {}).get("max_questions_total", 30) or 30))


def target_language(cfg: dict) -> str:
    return cfg.get("language", "ru")


# -----------------------------
# Session state
# -----------------------------
def init_state(cfg: dict):
    st.session_state.setdefault("cfg", cfg)
    st.session_state.setdefault("turn", 0)
    st.session_state.setdefault("max_turns", max_turns(cfg))
    st.session_state.setdefault("stage", "intake")
    st.session_state.setdefault("history", [])  # list of {turn, stage, q, a, meta}
    st.session_state.setdefault("current_q", None)  # dict question
    st.session_state.setdefault("name", "")
    st.session_state.setdefault("request", "")
    st.session_state.setdefault("finished", False)
    st.session_state.setdefault("client_report", None)
    st.session_state.setdefault("debug_last_error", None)

    # –ö—ç—à –¥–∞–π–¥–∂–µ—Å—Ç–∞, —á—Ç–æ–±—ã –Ω–µ —á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª—ã –∑–∞–Ω–æ–≤–æ
    st.session_state.setdefault("knowledge_digest", None)


def reset_all():
    for k in list(st.session_state.keys()):
        del st.session_state[k]
    st.rerun()


# -----------------------------
# OpenAI helpers
# -----------------------------
def get_client() -> OpenAI:
    # Streamlit Cloud: –¥–æ–±–∞–≤—å OPENAI_API_KEY –≤ Secrets
    return OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))


def compact_context(state: dict, keep_last: int = 6) -> str:
    """
    –°–∂–∏–º–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç: –¥–µ—Ä–∂–∏–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —à–∞–≥–æ–≤.
    """
    hist = state["history"][-keep_last:]
    lines = []
    for item in hist:
        q = item.get("q", "").strip()
        a = item.get("a", "").strip()
        stage = item.get("stage", "")
        lines.append(f"[{stage}] Q: {q}\nA: {a}")
    return "\n\n".join(lines).strip()


def safe_json(obj) -> dict:
    if isinstance(obj, dict):
        return obj
    return {}


def call_llm_json(system_text: str, user_text: str, cfg: dict, response_schema: dict, max_output_tokens: int = 600):
    client = get_client()
    m = model_name(cfg)
    return client.responses.create(
        model=m,
        input=[
            {"role": "system", "content": system_text},
            {"role": "user", "content": user_text},
        ],
        response_format={
            "type": "json_schema",
            "json_schema": response_schema,
        },
        max_output_tokens=max_output_tokens,
    )


# -----------------------------
# Question generator (HYBRID)
# -----------------------------
QUESTION_SCHEMA = {
    "name": "next_question",
    "schema": {
        "type": "object",
        "additionalProperties": False,
        "properties": {
            "question_id": {"type": "string"},
            "stage": {"type": "string"},
            "intent": {"type": "string"},
            "question_text": {"type": "string"},
            "answer_type": {"type": "string", "enum": ["text", "single", "multi"]},
            "options": {
                "type": "array",
                "items": {"type": "string"},
            },
            "required": {"type": "boolean"},
            "should_stop": {"type": "boolean"},
            "why_next": {"type": "string"},
        },
        "required": [
            "question_id",
            "stage",
            "intent",
            "question_text",
            "answer_type",
            "options",
            "required",
            "should_stop",
            "why_next",
        ],
    },
}


def next_question_llm(state: dict) -> dict:
    cfg = state["cfg"]

    if state["knowledge_digest"] is None:
        state["knowledge_digest"] = build_knowledge_digest()

    kd = state["knowledge_digest"]
    # —Å—É–ø–µ—Ä-–≤–∞–∂–Ω–æ: –ù–ï –∫–æ—Ä–º–∏–º –º–æ–¥–µ–ª—å –≤—Å–µ–º –ø–æ–¥—Ä—è–¥, –∏–Ω–∞—á–µ —Å–ª–æ–≤–∏–º TPM.
    # –î–∞–µ–º —Ç–æ–ª—å–∫–æ –¥–∞–π–¥–∂–µ—Å—Ç + –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç.
    ctx = compact_context(state, keep_last=6)

    # –ü—Ä–∞–≤–∏–ª–∞: –≥–∏–±—Ä–∏–¥ ‚Äî –ò–ò –∑–∞–¥–∞—ë—Ç –≤–æ–ø—Ä–æ—Å—ã, –Ω–æ:
    # 1) –Ω–µ –ø–æ–≤—Ç–æ—Ä—è–µ—Ç —É–∂–µ –∑–∞–¥–∞–Ω–Ω—ã–µ –ø–æ —Å–º—ã—Å–ª—É
    # 2) –Ω–µ ‚Äú–º—É—Å–æ–ª–∏—Ç‚Äù —ç–º–æ—Ü–∏–∏ –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ (–Ω–µ –±–æ–ª–µ–µ 1 —É—Ç–æ—á–Ω–µ–Ω–∏—è –ø–æ–¥—Ä—è–¥)
    # 3) –¥–µ—Ä–∂–∏—Ç —Ç–µ–º–ø: –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫–∞ -> –ø—Ä–∏–º–µ—Ä -> –ø—Ä–æ–≤–µ—Ä–∫–∞ –≤ –¥–µ—Ç—Å—Ç–≤–µ -> –ø—Ä–æ–≤–µ—Ä–∫–∞ –∞–Ω—Ç–∏–ø–∞—Ç—Ç–µ—Ä–Ω–∞ -> —Ñ–∏–∫—Å–∞—Ü–∏—è
    # 4) –µ—Å–ª–∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≤–∞—Ä–∏–∞–Ω—Ç—ã, —Ç–æ –æ–Ω–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ù–ï –ø—É—Å—Ç—ã–º–∏; –µ—Å–ª–∏ –ø—É—Å—Ç–æ ‚Äî –ø—É—Å—Ç—å –±—É–¥–µ—Ç text
    # 5) –ø–µ—Ä–≤—ã–µ 2 —à–∞–≥–∞ ‚Äî –∏–º—è –∏ –∑–∞–ø—Ä–æ—Å (intake)
    asked_intents = [h.get("intent") for h in state["history"]]
    last_intent = asked_intents[-1] if asked_intents else ""

    system_text = f"""
–¢—ã ‚Äî AI-–¥–∏–∞–≥–Ω–æ—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–æ–≤–æ–¥–∏—Ç –∂–∏–≤–æ–π —Ä–∞–∑–±–æ—Ä –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–æ–≤ (Neo Potentials).
–Ø–∑—ã–∫: {target_language(cfg)}.

–ñ–ï–°–¢–ö–ò–ï –ü–†–ê–í–ò–õ–ê:
- –ù–µ –ø–æ–≤—Ç–æ—Ä—è–π –≤–æ–ø—Ä–æ—Å—ã –ø–æ —Å–º—ã—Å–ª—É. –°–º–æ—Ç—Ä–∏ –∏—Å—Ç–æ—Ä–∏—é.
- –ù–µ –∑–∞–¥–∞–≤–∞–π "–ø–æ—á–µ–º—É?" –±–æ–ª—å—à–µ –æ–¥–Ω–æ–≥–æ —Ä–∞–∑–∞ –ø–æ–¥—Ä—è–¥. –ï—Å–ª–∏ —É–∂–µ –±—ã–ª —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å ‚Äî –ø–µ—Ä–µ—Ö–æ–¥–∏ –∫ —Ñ–∞–∫—Ç–∞–º/–ø—Ä–∏–º–µ—Ä–∞–º.
- –î–≤–∏–≥–∞–π—Å—è –ø–æ —ç—Ç–∞–ø–∞–º: intake -> now -> childhood -> behavior -> antipattern -> shifts(if needed) -> wrap.
- –ï—Å–ª–∏ answer_type = "single" –∏–ª–∏ "multi", options –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ù–ï –ø—É—Å—Ç—ã–º–∏ (>=2). –ò–Ω–∞—á–µ —Å—Ç–∞–≤—å answer_type="text" –∏ options=[].
- –í–æ–ø—Ä–æ—Å—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∫–æ—Ä–æ—Ç–∫–∏–µ, —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–µ, –±–µ–∑ –ª–µ–∫—Ü–∏–π.
- –ò—Å–ø–æ–ª—å–∑—É–π –∑–Ω–∞–Ω–∏—è –¢–û–õ–¨–ö–û –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ (–¥–∞–π–¥–∂–µ—Å—Ç –Ω–∏–∂–µ). –ù–µ –≤—ã–¥—É–º—ã–≤–∞–π —Ç–µ–æ—Ä–∏—é –≤–Ω–µ –Ω–∏—Ö.
- –ú–∞–∫—Å–∏–º—É–º –æ–¥–∏–Ω –≤–æ–ø—Ä–æ—Å –∑–∞ —à–∞–≥. –í–µ—Ä–Ω–∏ —Å—Ç—Ä–æ–≥–æ JSON –ø–æ —Å—Ö–µ–º–µ.

–í–ê–ñ–ù–û –ü–†–û UX:
- –ö–ª–∏–µ–Ω—Ç –æ—Ç–≤–µ—á–∞–µ—Ç –≤ –æ–¥–Ω–æ–º –ø–æ–ª–µ. –ù–µ –¥–æ–±–∞–≤–ª—è–π –ª–∏—à–Ω–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞.
- required=true –ø–æ—á—Ç–∏ –≤—Å–µ–≥–¥–∞. required=false —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –≤–æ–ø—Ä–æ—Å "–µ—Å–ª–∏ —Ö–æ—á–µ—à—å/–ø–æ –∂–µ–ª–∞–Ω–∏—é".

–î–ê–ô–î–ñ–ï–°–¢ –ó–ù–ê–ù–ò–ô (–∏—Å–ø–æ–ª—å–∑—É–π –∫–∞–∫ –±–∞–∑—É —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–æ–∫ –∏ –ª–æ–≥–∏–∫–∏):
{kd}
""".strip()

    user_text = f"""
–¢–ï–ö–£–©–ï–ï –°–û–°–¢–û–Ø–ù–ò–ï:
- turn: {state["turn"]} –∏–∑ {state["max_turns"]}
- stage: {state["stage"]}
- –∏–º—è: {state.get("name","").strip() or "(–Ω–µ –∑–∞–¥–∞–Ω–æ)"}
- –∑–∞–ø—Ä–æ—Å: {state.get("request","").strip() or "(–Ω–µ –∑–∞–¥–∞–Ω)"}
- –ø–æ—Å–ª–µ–¥–Ω–∏–π intent: {last_intent or "(–Ω–µ—Ç)"}
- —É–∂–µ –∑–∞–¥–∞–Ω–Ω—ã–µ intents: {asked_intents}

–ò–°–¢–û–†–ò–Ø (–ø–æ—Å–ª–µ–¥–Ω–∏–µ —à–∞–≥–∏):
{ctx or "(–ø–æ–∫–∞ –Ω–µ—Ç)"}

–°–ï–ô–ß–ê–°:
–°—Ñ–æ—Ä–º–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å —Ç–∞–∫, —á—Ç–æ–±—ã –æ–Ω:
1) –ø—Ä–æ–¥–≤–∏–Ω—É–ª —Ä–∞–∑–±–æ—Ä,
2) –ø—Ä–æ–≤–µ—Ä–∏–ª –≥–∏–ø–æ—Ç–µ–∑—ã –ø–æ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–∞–º/–ø–æ–∑–∏—Ü–∏—è–º,
3) –±—ã–ª –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –∏ –Ω–µ –ø–æ–≤—Ç–æ—Ä—è–ª—Å—è.

–í–µ—Ä–Ω–∏ should_stop=true —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —É–∂–µ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –∫—Ä–∞—Ç–∫–æ–π –∫–ª–∏–µ–Ω—Ç—Å–∫–æ–π –∫–∞—Ä—Ç–∏–Ω—ã.
""".strip()

    # retry logic for rate limits / transient errors
    last_err = None
    for _ in range(2):
        try:
            resp = call_llm_json(
                system_text=system_text,
                user_text=user_text,
                cfg=cfg,
                response_schema=QUESTION_SCHEMA,
                max_output_tokens=650,
            )
            data = resp.output_parsed  # dict
            return safe_json(data)
        except Exception as e:
            last_err = str(e)
            # –Ω–µ –≥–æ–≤–æ—Ä–∏–º "–ø–æ–¥–æ–∂–¥–∏ 30 —Å–µ–∫", –ø—Ä–æ—Å—Ç–æ –¥–∞–µ–º –∫–Ω–æ–ø–∫—É Retry –≤ UI
            time.sleep(0.2)

    st.session_state["debug_last_error"] = last_err
    # fallback –≤–æ–ø—Ä–æ—Å –µ—Å–ª–∏ LLM –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
    return {
        "question_id": f"fallback_{state['turn']}",
        "stage": state["stage"],
        "intent": "fallback",
        "question_text": "–£ –º–µ–Ω—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –ø–∞—É–∑–∞. –ù–∞–ø–∏—à–∏, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–¥–∏–Ω –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –ø—Ä–∏–º–µ—Ä –∏–∑ –∂–∏–∑–Ω–∏ (—Å–∏—Ç—É–∞—Ü–∏—è ‚Üí —á—Ç–æ —Ç—ã —Å–¥–µ–ª–∞–ª(–∞) ‚Üí –∫–∞–∫–æ–π –±—ã–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç), –∫–æ—Ç–æ—Ä—ã–π —É —Ç–µ–±—è –ø–æ–ª—É—á–∞–µ—Ç—Å—è –ª—É—á—à–µ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ –ª—é–¥–µ–π.",
        "answer_type": "text",
        "options": [],
        "required": True,
        "should_stop": False,
        "why_next": "Fallback –ø—Ä–∏ –æ—à–∏–±–∫–µ –º–æ–¥–µ–ª–∏/–ª–∏–º–∏—Ç–∞—Ö.",
    }


# -----------------------------
# Report generator
# -----------------------------
REPORT_SCHEMA = {
    "name": "client_report",
    "schema": {
        "type": "object",
        "additionalProperties": False,
        "properties": {
            "top3_potentials": {
                "type": "array",
                "items": {"type": "string"},
                "minItems": 3,
                "maxItems": 3,
            },
            "rows": {"type": "string"},
            "columns": {"type": "string"},
            "short_summary": {"type": "string"},
            "strengths_bullets": {
                "type": "array",
                "items": {"type": "string"},
                "minItems": 3,
                "maxItems": 6,
            },
            "energy_fillers_bullets": {
                "type": "array",
                "items": {"type": "string"},
                "minItems": 3,
                "maxItems": 6,
            },
            "next_step": {"type": "string"},
        },
        "required": [
            "top3_potentials",
            "rows",
            "columns",
            "short_summary",
            "strengths_bullets",
            "energy_fillers_bullets",
            "next_step",
        ],
    },
}


def generate_client_report(state: dict) -> dict:
    cfg = state["cfg"]
    if state["knowledge_digest"] is None:
        state["knowledge_digest"] = build_knowledge_digest()

    kd = state["knowledge_digest"]

    # –ü–æ–ª–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è, –Ω–æ –∞–∫–∫—É—Ä–∞—Ç–Ω–æ
    hist_lines = []
    for item in state["history"]:
        hist_lines.append(f"[{item.get('stage')}] {item.get('q')}\nA: {item.get('a')}")
    transcript = "\n\n".join(hist_lines)[:14000]

    system_text = f"""
–¢—ã —Ñ–æ—Ä–º–∏—Ä—É–µ—à—å –ö–õ–ò–ï–ù–¢–°–ö–ò–ô –º–∏–Ω–∏-—Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–æ–≤.
–Ø–∑—ã–∫: {target_language(cfg)}.

–ü—Ä–∞–≤–∏–ª–∞:
- –ù–ï –ø–æ–∫–∞–∑—ã–≤–∞–π —Å—ã—Ä—ã–µ –ª–æ–≥–∏/–±–∞–ª–ª—ã/–≤–µ—Å–∞.
- –î–∞–π —Ç–æ–ª—å–∫–æ –∫—Ä–∞—Ç–∫—É—é –∫–∞—Ä—Ç–∏–Ω—É: —Ç–æ–ø-3 –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–∞ + –∫–æ—Ä–æ—Ç–∫–æ —Ä—è–¥—ã/—Å—Ç–æ–ª–±—Ü—ã + —á—Ç–æ –¥–µ–ª–∞—Ç—å –¥–∞–ª—å—à–µ.
- –û–ø–∏—Ä–∞–π—Å—è –Ω–∞ –º–∞—Ç–µ—Ä–∏–∞–ª—ã (–¥–∞–π–¥–∂–µ—Å—Ç).
- –ï—Å–ª–∏ –µ—Å—Ç—å —Å–æ–º–Ω–µ–Ω–∏–µ ‚Äî –≤—ã–±–∏—Ä–∞–π –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–Ω–æ–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞–º–∏ –∫–ª–∏–µ–Ω—Ç–∞ –∏ —Ñ–∞–∫—Ç–∞–º–∏.

–î–ê–ô–î–ñ–ï–°–¢:
{kd}
""".strip()

    user_text = f"""
–ò–º—è –∫–ª–∏–µ–Ω—Ç–∞: {state.get('name','')}
–ó–∞–ø—Ä–æ—Å: {state.get('request','')}

–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç:
{transcript}

–°–æ–±–µ—Ä–∏ –∫–ª–∏–µ–Ω—Ç—Å–∫–∏–π –º–∏–Ω–∏-–æ—Ç—á–µ—Ç.
""".strip()

    try:
        resp = call_llm_json(
            system_text=system_text,
            user_text=user_text,
            cfg=cfg,
            response_schema=REPORT_SCHEMA,
            max_output_tokens=850,
        )
        return safe_json(resp.output_parsed)
    except Exception as e:
        st.session_state["debug_last_error"] = str(e)
        return {
            "top3_potentials": ["(–Ω–µ —É–¥–∞–ª–æ—Å—å)", "(–Ω–µ —É–¥–∞–ª–æ—Å—å)", "(–Ω–µ —É–¥–∞–ª–æ—Å—å)"],
            "rows": "‚Äî",
            "columns": "‚Äî",
            "short_summary": "–ù–µ —É–¥–∞–ª–æ—Å—å —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –æ—Ç—á–µ—Ç –∏–∑-–∑–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –æ—à–∏–±–∫–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å.",
            "strengths_bullets": ["‚Äî", "‚Äî", "‚Äî"],
            "energy_fillers_bullets": ["‚Äî", "‚Äî", "‚Äî"],
            "next_step": "–ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É –∏ –ø—Ä–æ–π—Ç–∏ —Å–Ω–æ–≤–∞.",
        }


# -----------------------------
# UI helpers
# -----------------------------
def render_question(q: dict):
    # –∑–∞—â–∏—Ç–∞ –æ—Ç –ø—É—Å—Ç—ã—Ö options
    q_type = q.get("answer_type", "text")
    options = q.get("options") or []

    if q_type in ("single", "multi") and len(options) < 2:
        q_type = "text"
        options = []

    st.markdown(f"### {q.get('question_text','').strip()}")

    answer_key = f"answer_{st.session_state['turn']}"
    answer = None

    if q_type == "single":
        answer = st.radio("–í—ã–±–µ—Ä–∏ –æ–¥–∏–Ω –≤–∞—Ä–∏–∞–Ω—Ç:", options, key=answer_key)
    elif q_type == "multi":
        answer = st.multiselect("–í—ã–±–µ—Ä–∏ –≤–∞—Ä–∏–∞–Ω—Ç—ã:", options, key=answer_key)
    else:
        answer = st.text_area("–û—Ç–≤–µ—Ç:", height=130, key=answer_key)

    return answer, answer_key


def validate_answer(q: dict, answer) -> bool:
    if not q.get("required", True):
        return True
    q_type = q.get("answer_type", "text")
    options = q.get("options") or []
    if q_type in ("single", "multi") and len(options) < 2:
        q_type = "text"

    if q_type == "single":
        return isinstance(answer, str) and answer.strip() != ""
    if q_type == "multi":
        return isinstance(answer, list) and len(answer) > 0
    return isinstance(answer, str) and answer.strip() != ""


# -----------------------------
# Main app
# -----------------------------
st.set_page_config(page_title="NEO –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–æ–≤", page_icon="üß≠", layout="centered")

cfg = load_json(DEFAULT_CONFIG_PATH)
init_state(cfg)

# Minimal header
st.title("–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–æ–≤")
st.caption("–§–æ—Ä–º–∞—Ç: –∂–∏–≤–æ–π —Ä–∞–∑–±–æ—Ä. –í–æ–ø—Ä–æ—Å—ã —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç –ò–ò –ø–æ –ª–æ–≥–∏–∫–µ —ç—Ç–∞–ø–æ–≤, –±–µ–∑ –ø–æ–≤—Ç–æ—Ä–æ–≤. –í –∫–æ–Ω—Ü–µ ‚Äî –∫–æ—Ä–æ—Ç–∫–∞—è –∫–∞—Ä—Ç–∏–Ω–∞ + —Å–ª–µ–¥—É—é—â–∏–π —à–∞–≥.")

# Reset button
col_a, col_b = st.columns([1, 1])
with col_a:
    if st.button("üîÑ –°–±—Ä–æ—Å–∏—Ç—å –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É"):
        reset_all()

# Progress line
st.write(f"–•–æ–¥: –≤–æ–ø—Ä–æ—Å {min(st.session_state['turn'] + 1, st.session_state['max_turns'])} –∏–∑ {st.session_state['max_turns']}  |  —Ñ–∞–∑–∞: {st.session_state['stage']}")

# If finished: show report
if st.session_state["finished"]:
    st.success("–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ ‚úÖ")
    rep = st.session_state.get("client_report")
    if not rep:
        rep = generate_client_report(st.session_state)
        st.session_state["client_report"] = rep

    st.markdown(f"**–ò–º—è:** {st.session_state.get('name','') or '‚Äî'}")
    st.markdown(f"**–ó–∞–ø—Ä–æ—Å:** {st.session_state.get('request','') or '‚Äî'}")

    st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç (–∫—Ä–∞—Ç–∫–æ)")
    st.markdown(f"**–¢–æ–ø-3 –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–∞:** {', '.join(rep.get('top3_potentials', []))}")
    st.markdown(f"**–†—è–¥—ã:** {rep.get('rows','‚Äî')}")
    st.markdown(f"**–°—Ç–æ–ª–±—Ü—ã:** {rep.get('columns','‚Äî')}")
    st.write(rep.get("short_summary", ""))

    st.subheader("–í–∞—à–∏ —Å–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã")
    for b in rep.get("strengths_bullets", []):
        st.write(f"‚Ä¢ {b}")

    st.subheader("–ß—Ç–æ –≤–∞—Å –Ω–∞–ø–æ–ª–Ω—è–µ—Ç")
    for b in rep.get("energy_fillers_bullets", []):
        st.write(f"‚Ä¢ {b}")

    st.subheader("–°–ª–µ–¥—É—é—â–∏–π —à–∞–≥")
    st.write(rep.get("next_step", ""))

    # Download transcript (client-friendly)
    hist = st.session_state["history"]
    lines = []
    for item in hist:
        lines.append(f"{item.get('stage','')} | {item.get('intent','')}\nQ: {item.get('q','')}\nA: {item.get('a','')}\n")
    txt = "\n".join(lines)
    st.download_button("üì• –°–∫–∞—á–∞—Ç—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç (TXT)", data=txt.encode("utf-8"), file_name="neo_transcript.txt", mime="text/plain")

    # Optional: show last error only if exists (small)
    if st.session_state.get("debug_last_error"):
        st.caption("–¢–µ—Ö. –∑–∞–º–µ—Ç–∫–∞: –±—ã–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ –º–æ–¥–µ–ª–∏ (–º–æ–∂–Ω–æ –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å, –µ—Å–ª–∏ –≤—Å—ë –ø—Ä–æ—à–ª–æ).")
    st.stop()

# If max turns reached => finish
if st.session_state["turn"] >= st.session_state["max_turns"]:
    st.session_state["finished"] = True
    st.rerun()

# Get / create current question
if st.session_state["current_q"] is None:
    q = next_question_llm(st.session_state)

    # stage management (intake helpers)
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º stage –∏–∑ –≤–æ–ø—Ä–æ—Å–∞, –µ—Å–ª–∏ –ø—Ä–∏—à–ª–æ
    if q.get("stage"):
        st.session_state["stage"] = q["stage"]

    st.session_state["current_q"] = q
else:
    q = st.session_state["current_q"]

# Render question
answer, answer_key = render_question(q)

# Buttons
col1, col2 = st.columns([1, 1])
with col1:
    go_next = st.button("–î–∞–ª–µ–µ ‚ûú")
with col2:
    finish_now = st.button("–ó–∞–≤–µ—Ä—à–∏—Ç—å —Å–µ–π—á–∞—Å")

if finish_now:
    st.session_state["finished"] = True
    st.rerun()

if go_next:
    if not validate_answer(q, answer):
        st.warning("–í—ã–±–µ—Ä–∏ –≤–∞—Ä–∏–∞–Ω—Ç –∏–ª–∏ –Ω–∞–ø–∏—à–∏ –æ—Ç–≤–µ—Ç.")
        st.stop()

    # Save name/request when intake
    qid = q.get("question_id", f"q_{st.session_state['turn']}")
    intent = q.get("intent", "")
    stage = q.get("stage", st.session_state["stage"])
    q_text = q.get("question_text", "")

    # intake capture: –µ—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –ø—Ä–æ –∏–º—è/–∑–∞–ø—Ä–æ—Å ‚Äî –≤—ã—Ç–∞—Å–∫–∏–≤–∞–µ–º –∏–∑ —Ç–µ–∫—Å—Ç–∞
    if intent in ("ask_name", "q_name", "name"):
        st.session_state["name"] = (answer or "").strip()
    if intent in ("ask_request", "q_request", "request"):
        st.session_state["request"] = (answer or "").strip()

    # –µ—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π "–∏–º—è+–∑–∞–ø—Ä–æ—Å" ‚Äî –ø—Ä–æ–±—É–µ–º –≤—ã—Ç–∞—â–∏—Ç—å
    if intent in ("ask_name_and_request", "intake"):
        txt = (answer or "").strip()
        # –æ—á–µ–Ω—å –º—è–≥–∫–∏–π –ø–∞—Ä—Å–µ—Ä: –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –∏–º—è, –æ—Å—Ç–∞–ª—å–Ω–æ–µ –∑–∞–ø—Ä–æ—Å
        parts = [p.strip() for p in txt.split("\n") if p.strip()]
        if parts:
            # –µ—Å–ª–∏ –ø–æ—Ö–æ–∂–µ –Ω–∞ "–ú–µ–Ω—è ...", —Ç–æ –æ—Å—Ç–∞–≤–∏–º –∫–∞–∫ –µ—Å—Ç—å
            if len(parts) == 1:
                # –æ—Å—Ç–∞–≤–∏–º –≤ request, –∏–º—è –µ—Å–ª–∏ —É–∂–µ –±—ã–ª–æ ‚Äî –Ω–µ —Ç—Ä–æ–≥–∞–µ–º
                if not st.session_state["name"]:
                    st.session_state["name"] = "‚Äî"
                st.session_state["request"] = parts[0]
            else:
                if not st.session_state["name"] or st.session_state["name"] == "‚Äî":
                    st.session_state["name"] = parts[0]
                st.session_state["request"] = " ".join(parts[1:])

    # Append to history
    st.session_state["history"].append(
        {
            "turn": st.session_state["turn"],
            "question_id": qid,
            "intent": intent,
            "stage": stage,
            "q": q_text,
            "a": answer if isinstance(answer, str) else json.dumps(answer, ensure_ascii=False),
            "meta": {"why_next": q.get("why_next", "")},
        }
    )

    # advance
    st.session_state["turn"] += 1
    st.session_state["current_q"] = None

    # clear widget for next question
    try:
        del st.session_state[answer_key]
    except Exception:
        pass

    # stop if model says stop
    if q.get("should_stop") is True and st.session_state["turn"] >= 8:
        st.session_state["finished"] = True

    st.rerun()